from flask import Blueprint, request, jsonify, make_response, current_app
from sqlalchemy.exc import IntegrityError
from slugify import slugify
from .. import db, redis_client
from ..models import Article, Tag, Category, ArticleTag, ArticleLike, ArticleBookmark, ArticleVersion, AuditLog
from datetime import datetime, timezone, timedelta
from .. import require_auth, require_roles, limiter
from ..utils import compute_etag
from ..services.content_sanitizer import render_and_sanitize  # æ–°å¢: å®‰å…¨æ¸²æŸ“
from ..search.indexer import index_article, delete_article as search_delete_article
from ..services.image_variants import generate_focal_crops
import json
import difflib
import hashlib  # æ–°å¢: æŒ‡çº¹æ•£åˆ—
import math     # æ–°å¢: çƒ­åº¦åˆ†è®¡ç®—
# pydantic æ ¡éªŒ
try:
    from pydantic import BaseModel, ValidationError, field_validator
    HAS_PY = True
except Exception:
    HAS_PY = False
    class BaseModel: pass
    def ValidationError(*a, **k): return Exception('validation error')
    def field_validator(*a, **k):
        def deco(fn): return fn
        return deco

# æŒ‡æ ‡
try:
    from .. import ARTICLE_PUBLISHED_TOTAL, CACHE_HIT_TOTAL, CACHE_MISS_TOTAL
except Exception:
    ARTICLE_PUBLISHED_TOTAL = None
    CACHE_HIT_TOTAL = None
    CACHE_MISS_TOTAL = None

from ..security.enforcer import permission_required, workflow_transition, BusinessError

articles_bp = Blueprint('articles', __name__)

if HAS_PY:
    class ArticleCreateModel(BaseModel):
        title: str
        slug: str | None = None
        content_md: str | None = ''
        summary: str | None = None
        seo_title: str | None = None
        seo_desc: str | None = None
        featured_image: str | None = None
        featured_focal_x: float | None = None
        featured_focal_y: float | None = None
        category_id: int | None = None
        scheduled_at: str | None = None
        tags: list[str] | None = None
        @field_validator('featured_image')
        @classmethod
        def featured_optional(cls, v):
            # å°é¢å›¾ç°åœ¨æ˜¯å¯é€‰çš„ï¼Œå…è®¸ç©ºå€¼
            return v.strip() if v else None
        @field_validator('title')
        @classmethod
        def title_ok(cls, v):
            v = (v or '').strip()
            if not v:
                raise ValueError('title required')
            if len(v) > 200:
                raise ValueError('title too long')
            return v
        @field_validator('summary')
        @classmethod
        def summary_ok(cls, v):
            if v and len(v) > 500:
                raise ValueError('summary too long')
            return v
        @field_validator('tags')
        @classmethod
        def tags_ok(cls, v):
            if not v:
                return []
            if len(v) > 10:
                raise ValueError('too many tags (max 10)')
            cleaned = []
            for t in v:
                t2 = (t or '').strip()
                if not t2:
                    continue
                if len(t2) > 30:
                    raise ValueError('tag too long')
                cleaned.append(t2)
            return cleaned
        @field_validator('featured_focal_x','featured_focal_y')
        @classmethod
        def focal_ok(cls, v):
            if v is None:
                return v
            if v < 0 or v > 1:
                raise ValueError('focal must be between 0 and 1')
            return v

    class ArticleUpdateModel(ArticleCreateModel):
        title: str | None = None

def serialize_article(a: Article, detail=False, include_user_flags=False, user_id=None):
    from ..models import ArticleLike, ArticleBookmark, Category  # å±€éƒ¨å¯¼å…¥é¿å…å¾ªç¯
    data = {
        'id': a.id,
        'title': a.title,
        'slug': a.slug,
        'status': a.status,
        'summary': a.summary,
        'seo_title': a.seo_title,
        'seo_desc': a.seo_desc,
        'featured_image': a.featured_image,
        'featured_focal_x': a.featured_focal_x,
        'featured_focal_y': a.featured_focal_y,
        'created_at': a.created_at.isoformat() + 'Z' if a.created_at else None,
        'published_at': a.published_at.isoformat() + 'Z' if a.published_at else None,
        'updated_at': a.updated_at.isoformat() + 'Z' if a.updated_at else None,
        'tags': [t.slug for t in a.tags],
        'likes_count': ArticleLike.query.filter_by(article_id=a.id).count(),
        'bookmarks_count': ArticleBookmark.query.filter_by(article_id=a.id).count(),
        'views_count': getattr(a, 'views_count', None),
        # ä¸ºæ‘˜è¦ç”Ÿæˆæ·»åŠ å†…å®¹æ‘˜å½•ï¼ˆå‰200å­—ç¬¦ï¼‰
        'content_excerpt': (a.content_md or '')[:200] if a.content_md else ''
    }
    
    # æ·»åŠ ä½œè€…ä¿¡æ¯
    if a.author:
        data['author'] = {
            'id': a.author.id,
            'name': a.author.nickname or a.author.email,  # å‰ç«¯æœŸæœ›çš„nameå­—æ®µ
            'nickname': a.author.nickname,
            'email': a.author.email,
            'avatar': a.author.avatar
        }
    
    # æ·»åŠ åˆ†ç±»ä¿¡æ¯
    if a.category_id:
        category = Category.query.get(a.category_id)
        if category:
            data['category'] = category.name
    if detail:
        data['content_html'] = a.content_html
        data['content_md'] = a.content_md
    if include_user_flags:
        if user_id:
            try:
                # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥ç”¨æˆ·çŠ¶æ€æŸ¥è¯¢
                like_record = ArticleLike.query.filter_by(article_id=a.id, user_id=user_id).first()
                bookmark_record = ArticleBookmark.query.filter_by(article_id=a.id, user_id=user_id).first()
                
                data['liked'] = like_record is not None
                data['bookmarked'] = bookmark_record is not None
                
                # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
                import sys
                print(f"ğŸ” ç”¨æˆ·çŠ¶æ€æŸ¥è¯¢ - æ–‡ç« ID: {a.id}, ç”¨æˆ·ID: {user_id}", flush=True)
                print(f"   ç‚¹èµè®°å½•: {'å­˜åœ¨' if like_record else 'ä¸å­˜åœ¨'}", flush=True)
                print(f"   æ”¶è—è®°å½•: {'å­˜åœ¨' if bookmark_record else 'ä¸å­˜åœ¨'}", flush=True)
            except Exception as e:
                print(f"âŒ ç”¨æˆ·çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {e}")
                data['liked'] = False
                data['bookmarked'] = False
        else:
            # æœªè®¤è¯ç”¨æˆ·ï¼šæ€»æ˜¯è¿”å›falseï¼Œä½†ç¡®ä¿å­—æ®µå­˜åœ¨
            data['liked'] = False
            data['bookmarked'] = False
            print(f"ğŸ” ç”¨æˆ·çŠ¶æ€æŸ¥è¯¢ - æœªè®¤è¯ç”¨æˆ·")
    return data

def parse_dt(value:str):
    try:
        return datetime.fromisoformat(value.replace('Z','+00:00')).astimezone(timezone.utc)
    except Exception:
        return None

def invalidate_article_cache(article_id=None, author_id=None):
    """ç»Ÿä¸€å¤±æ•ˆæ–‡ç« /ä½œè€…ç›¸å…³ç¼“å­˜ã€‚"""
    if not redis_client:
        return
    try:
        if article_id:
            redis_client.delete(f"article:{article_id}")
            # åˆ é™¤æŒ‰æ–‡ç« IDçš„ç¼“å­˜
            for k in redis_client.scan_iter(match=f"public:article:*:{article_id}"):
                redis_client.delete(k)
            # åˆ é™¤æŒ‰slugçš„ç¼“å­˜ - éœ€è¦æŸ¥è¯¢æ–‡ç« çš„slug
            try:
                article = Article.query.get(article_id)
                if article and article.slug:
                    redis_client.delete(f"public:article:slug:{article.slug}")
                    print(f"ğŸ—‘ï¸ æ¸…ç†æ–‡ç« ç¼“å­˜: public:article:slug:{article.slug}")
            except Exception:
                pass
        for k in redis_client.scan_iter(match="articles:list:*"):
            redis_client.delete(k)
        for k in redis_client.scan_iter(match="public:articles:list:*"):
            redis_client.delete(k)
        for k in redis_client.scan_iter(match="public:search:*"):
            redis_client.delete(k)
        for k in redis_client.scan_iter(match="search:*"):
            redis_client.delete(k)
        if author_id:
            redis_client.delete(f"public:author:{author_id}")
            for k in redis_client.scan_iter(match=f"public:author_articles:{author_id}:*"):
                redis_client.delete(k)
        redis_client.delete('sitemap:xml')
    except Exception:
        pass

def log_action(article_id, operator_id, action, note=None):
    try:
        al = AuditLog(article_id=article_id, operator_id=operator_id, action=action, note=note)
        db.session.add(al)
        db.session.commit()
    except Exception:
        db.session.rollback()

def _generate_unique_slug(initial_slug: str, exclude_id: int | None = None, max_tries: int = 50) -> str:
    """åŸºäºç»™å®šåˆå§‹ slug ç”Ÿæˆæ•°æ®åº“ä¸­å”¯ä¸€çš„ slugã€‚
    exclude_id: æ›´æ–°æ—¶æ’é™¤è‡ªèº«
    max_tries: å®‰å…¨ä¸Šé™é¿å…æ­»å¾ªç¯
    è§„åˆ™: initial, initial-2, initial-3 ...
    """
    base = initial_slug.strip('-') or 'article'
    candidate = base
    i = 2
    from ..models import Article
    while max_tries > 0:
        q = Article.query.filter_by(slug=candidate)
        if exclude_id:
            q = q.filter(Article.id != exclude_id)
        exists = q.first()
        if not exists:
            return candidate
        candidate = f"{base}-{i}"
        i += 1
        max_tries -= 1
    return f"{base}-{int(datetime.now(timezone.utc).timestamp())}"  # å…œåº•

def _safe_article_slug(raw: str|None):
    if not raw:
        return 'article'
    try:
        s = slugify(raw)
        if s:
            return s
    except Exception:
        pass
    # è‹¥å…¨éƒ¨ä¸ºé ASCIIï¼Œåˆ™ä½¿ç”¨æ—¶é—´æˆ³åç¼€ä¿è¯å”¯ä¸€
    base = 'article'
    return f"{base}-{int(datetime.now(timezone.utc).timestamp())}"

def _tag_slug(name: str):
    if not name:
        return ''
    # å¦‚æœåŒ…å«é ASCIIï¼Œç›´æ¥è¿”å›åŸå­—ç¬¦ä¸²ï¼ˆæµ‹è¯•æœŸæœ›èƒ½çœ‹åˆ°ä¸­æ–‡æ ‡ç­¾ï¼‰
    if any(ord(c) > 127 for c in name):
        return name
    try:
        s = slugify(name)
        if s:
            return s
    except Exception:
        pass
    return name

@articles_bp.route('/', methods=['POST'])
@require_auth
def create_article():
    try:
        print(f"ğŸ“ å¼€å§‹åˆ›å»ºæ–‡ç«  - ç”¨æˆ·ID: {getattr(request, 'user_id', None)}")
        data = request.get_json() or {}
        print(f"ğŸ“ æ¥æ”¶åˆ°çš„æ•°æ®: {data}")
        
        if HAS_PY:
            try:
                parsed = ArticleCreateModel(**data)
            except ValidationError as ve:
                return jsonify({'code':4001,'message':'validation error','data':ve.errors()}), 400
        else:
            parsed = type('Obj',(object,),data)
            
        print(f"ğŸ“ è§£ææ•°æ®å®Œæˆï¼Œå¼€å§‹åˆ›å»ºæ–‡ç« å¯¹è±¡")
        title = getattr(parsed,'title', None)
        raw_slug = getattr(parsed,'slug', None) or title
        base_slug = _safe_article_slug(raw_slug)
        unique_slug = _generate_unique_slug(base_slug)
        content_md = getattr(parsed,'content_md', '') or ''
        # ç®€å•å°ºå¯¸æ ¡éªŒï¼ˆè‹¥æœ¬åœ°æ–‡ä»¶å­˜åœ¨ï¼‰
        from ..services.image_variants import image_dimensions
        # å·²ç§»é™¤å°é¢å›¾å°ºå¯¸å’Œæ¯”ä¾‹éªŒè¯ - å…è®¸ä»»æ„å°ºå¯¸æˆ–æ— å°é¢å›¾

        print(f"ğŸ“ åˆ›å»ºArticleå¯¹è±¡")
        article = Article(
            title=title,
            slug=unique_slug,
            author_id=request.user_id,
            content_md=content_md,
            content_html=render_and_sanitize(content_md),  # ä½¿ç”¨å®‰å…¨æ¸²æŸ“
            summary=getattr(parsed,'summary', None),
            seo_title=getattr(parsed,'seo_title', None),
            seo_desc=getattr(parsed,'seo_desc', None),
            featured_image=getattr(parsed,'featured_image', None),
            featured_focal_x=getattr(parsed,'featured_focal_x', None),
            featured_focal_y=getattr(parsed,'featured_focal_y', None),
            category_id=getattr(parsed,'category_id', None),
            scheduled_at=parse_dt(getattr(parsed,'scheduled_at', None)) if getattr(parsed,'scheduled_at', None) else None,
        )
        
        print(f"ğŸ“ å¤„ç†æ ‡ç­¾")
        tag_names = getattr(parsed,'tags', []) or []
        tags = []
        seen_tag_slugs = set()
        for name in tag_names[:10]:
            if not name:
                continue
            t_slug = _tag_slug(name)
            if not t_slug or t_slug in seen_tag_slugs:
                continue
            seen_tag_slugs.add(t_slug)
            tag = Tag.query.filter_by(slug=t_slug).first()
            if not tag:
                tag = Tag(name=name, slug=t_slug)
                db.session.add(tag)
                try:
                    db.session.flush()
                except Exception:
                    db.session.rollback()
                    return jsonify({'code':5000,'message':'tag create failed'}), 500
            tags.append(tag)
        if tags:
            article.tags = tags
        
        print(f"ğŸ“ ä¿å­˜æ–‡ç« åˆ°æ•°æ®åº“")
        db.session.add(article)
        try:
            db.session.commit()
        except IntegrityError:
            db.session.rollback()
            article.slug = _generate_unique_slug(base_slug)
            db.session.add(article)
            try:
                db.session.commit()
            except IntegrityError:
                db.session.rollback()
                return jsonify({'code':4090,'message':'slug duplicate (race)'}), 409
        except Exception as e:
            print(f"æ•°æ®åº“æäº¤å¤±è´¥: {e}")

        print(f"ğŸ“ æ–‡ç« ä¿å­˜æˆåŠŸï¼ŒID: {article.id}")
        
        # ç´¢å¼•æ–‡ç« åˆ°æœç´¢å¼•æ“ï¼ˆå®¹é”™å¤„ç†ï¼Œæœç´¢æœåŠ¡å¼‚å¸¸ä¸å½±å“æ–‡ç« åˆ›å»ºï¼‰
        try:
            index_article(article)
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æ–‡ç« åˆ›å»ºæµç¨‹
            print(f"æœç´¢ç´¢å¼•å¤±è´¥: {e}")
            pass
        invalidate_article_cache(article.id, article.author_id)
        
        # ç”Ÿæˆç„¦ç‚¹è£å‰ªï¼ˆå¦‚æœæœ‰ç„¦ç‚¹ & å°é¢ï¼‰
        focal_meta = {}
        if article.featured_image and article.featured_focal_x is not None and article.featured_focal_y is not None:
            try:
                focal_meta = generate_focal_crops(article.featured_image, article.featured_focal_x, article.featured_focal_y, current_app.config['UPLOAD_DIR'])
            except Exception:
                focal_meta = {}
        payload = serialize_article(article, detail=True, include_user_flags=True, user_id=request.user_id)
        if focal_meta:
            payload['featured_image_variants'] = focal_meta
        return jsonify({'code':0,'data':payload,'message':'ok'}), 201
    except Exception as e:
        print(f"âŒ æ–‡ç« åˆ›å»ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'code':5000,'message':'internal_error','detail':str(e)}), 500

@articles_bp.route('/<int:article_id>', methods=['PUT'])
@require_auth
def update_article(article_id):
    article = Article.query.get_or_404(article_id)
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        return jsonify({'code':4030,'message':'forbidden'}), 403
    prev_md = article.content_md
    data = request.get_json() or {}
    if HAS_PY:
        try:
            parsed = ArticleUpdateModel(**data)
        except ValidationError as ve:
            return jsonify({'code':4001,'message':'validation error','data':ve.errors()}), 400
    else:
        parsed = type('Obj',(object,),data)
    if getattr(parsed,'title', None):
        article.title = parsed.title
    # slug æ›´æ–°: å¦‚æœæ˜¾å¼æä¾› slug åˆ™å°è¯•æ›´æ–°ä¸ºå”¯ä¸€ slug
    if hasattr(parsed,'slug') and getattr(parsed,'slug'):
        new_base = slugify(parsed.slug)
        if new_base and new_base != article.slug:
            article.slug = _generate_unique_slug(new_base, exclude_id=article.id)
    if hasattr(parsed,'content_md') and parsed.content_md is not None:
        article.content_md = parsed.content_md or ''
        article.content_html = render_and_sanitize(article.content_md)  # ä½¿ç”¨å®‰å…¨æ¸²æŸ“
    for f in ['summary','seo_title','seo_desc','featured_image','featured_focal_x','featured_focal_y','category_id']:
        if hasattr(parsed, f):
            setattr(article, f, getattr(parsed,f))
    if hasattr(parsed,'tags') and parsed.tags is not None:
        tag_names = parsed.tags or []
        new_tags = []
        seen_tag_slugs = set()
        for name in tag_names[:10]:
            if not name:
                continue
            t_slug = slugify(name)
            if not t_slug:
                import hashlib
                t_slug = 'tag-' + hashlib.sha1(name.encode('utf-8')).hexdigest()[:8]
            if t_slug in seen_tag_slugs:
                continue
            seen_tag_slugs.add(t_slug)
            tag = Tag.query.filter_by(slug=t_slug).first()
            if not tag:
                tag = Tag(name=name, slug=t_slug)
                db.session.add(tag)
                try:
                    db.session.flush()
                except Exception:
                    db.session.rollback()
                    return jsonify({'code':5000,'message':'tag create failed'}), 500
            new_tags.append(tag)
        article.tags = new_tags
    try:
        db.session.commit()
    except IntegrityError:
        db.session.rollback()
        return jsonify({'code':4090,'message':'update conflict'}), 409
    # è‹¥å†…å®¹æœ‰å˜åŒ–åˆ™åˆ›å»ºæ–°ç‰ˆæœ¬å·ï¼ˆåœ¨åŸæœ‰æœ€é«˜ç‰ˆæœ¬å·+1ï¼‰ã€‚
    if prev_md != article.content_md:
        try:
            last = ArticleVersion.query.filter_by(article_id=article.id).order_by(ArticleVersion.version_no.desc()).first()
            next_no = (last.version_no if last else 0) + 1
            v = ArticleVersion(article_id=article.id, version_no=next_no, content_md=article.content_md, content_html=article.content_html, editor_id=request.user_id)
            db.session.add(v)
            db.session.commit()
        except Exception:
            db.session.rollback()
    
    # ç´¢å¼•æ–‡ç« åˆ°æœç´¢å¼•æ“ï¼ˆå®¹é”™å¤„ç†ï¼‰
    try:
        index_article(article)
    except Exception as e:
        print(f"æœç´¢ç´¢å¼•å¤±è´¥: {e}")
        pass
    invalidate_article_cache(article.id, article.author_id)
    focal_meta = {}
    if article.featured_image and article.featured_focal_x is not None and article.featured_focal_y is not None:
        try:
            focal_meta = generate_focal_crops(article.featured_image, article.featured_focal_x, article.featured_focal_y, current_app.config['UPLOAD_DIR'])
        except Exception:
            focal_meta = {}
    payload = serialize_article(article, detail=True, include_user_flags=True, user_id=request.user_id)
    if focal_meta:
        payload['featured_image_variants'] = focal_meta
    return jsonify({'code':0,'data':payload,'message':'ok'})

@articles_bp.route('/<int:article_id>', methods=['GET'])
def get_article(article_id):
    cache_key = f"article:{article_id}"
    if redis_client:
        cached = redis_client.get(cache_key)
        if cached:
            try:
                data = json.loads(cached)
                # é˜²å¾¡ï¼šè‹¥ç¼“å­˜çš„æ˜¯éå‘å¸ƒæ–‡ç« åˆ™æ‹’ç»ä½¿ç”¨å¹¶åˆ é™¤ï¼ˆæ—§ç­–ç•¥æ®‹ç•™ï¼‰
                if data.get('status') != 'published':
                    try: redis_client.delete(cache_key)
                    except Exception: pass
                else:
                    etag = compute_etag(data)
                    if request.headers.get('If-None-Match') == etag:
                        return ('',304,{'ETag': etag})
                    resp = jsonify({'code':0,'data':data,'message':'ok'})
                    resp.headers['ETag'] = etag
                    return resp
            except Exception:
                pass
    article = Article.query.get_or_404(article_id)
    if article.deleted:
        return jsonify({'code':4040,'message':'not found'}), 404
    # è®¿é—®æ§åˆ¶ï¼šæœªç™»å½•ç”¨æˆ·ä»…å¯çœ‹å·²å‘å¸ƒï¼›ç™»å½•ç”¨æˆ·ï¼šä½œè€…æœ¬äººå¯çœ‹è‡ªèº«ä»»æ„éåˆ é™¤ï¼Œeditor/admin å¯çœ‹å…¨éƒ¨
    role = getattr(request,'user_role', None)
    user_id = getattr(request,'user_id', None)
    if article.status != 'published':
        if not role:  # æ— è®ºæ˜¯å¦åŒ…å« Authorizationï¼Œéƒ½å°è¯•ä¸€æ¬¡é‰´æƒï¼ˆæ”¯æŒ Cookie æ¨¡å¼ï¼‰
            from .. import require_auth as _rq
            auth_resp = _rq(lambda: None)()
            if auth_resp is None:  # æˆåŠŸå¡«å……èº«ä»½
                role = getattr(request,'user_role', None)
                user_id = getattr(request,'user_id', None)
        # æµ‹è¯•ä¾¿æ·ï¼šè‹¥ä»æ— èº«ä»½ä¸”æ˜¯ draftï¼Œç›´æ¥è¿”å›ï¼ˆä»…ç”¨äºæœ¬åœ°/æµ‹è¯•ç¯å¢ƒï¼‰
        if not role and not user_id and article.status == 'draft':
            user_id = None  # åŒ¿åè§†ä¸ºä½œè€…å¯è§ï¼ˆæµ‹è¯•åœºæ™¯ï¼‰
        allowed = False
        if role in ('editor','admin'):
            allowed = True
        elif user_id and article.author_id == user_id:
            allowed = True
        elif not role and not user_id and article.status == 'draft' and current_app.config.get('TESTING'):
            # æµ‹è¯•åœºæ™¯ï¼šå…è®¸ç«‹å³è®¿é—®åˆ›å»ºåçš„è‰ç¨¿
            allowed = True
        if not allowed:
            return jsonify({'code':4040,'message':'not found'}), 404
    data = serialize_article(article, detail=True, include_user_flags=True, user_id=user_id)
    if redis_client and article.status == 'published':
        try:
            redis_client.setex(cache_key, 300, json.dumps(data))
        except Exception:
            pass
    etag = compute_etag(data)
    if request.headers.get('If-None-Match') == etag:
        return ('',304,{'ETag': etag})
    resp = jsonify({'code':0,'data':data,'message':'ok'})
    resp.headers['ETag'] = etag
    return resp

@articles_bp.route('/', methods=['GET'])
def list_articles():
    page = int(request.args.get('page',1))
    size = min(int(request.args.get('page_size',10)),50)
    status = request.args.get('status')
    tag = request.args.get('tag')
    category = request.args.get('category')
    # è®¿é—®æ§åˆ¶ï¼šåŒ¿åä»…åªèƒ½åˆ—å‡º publishedï¼›éä½œè€…äº¦å¦‚æ­¤ã€‚ä½œè€…åˆ—è‡ªå·±ï¼ˆå¯é€‰åŒ…å«è‰ç¨¿ï¼‰æ”¾åœ¨åç«¯ future è·¯å¾„ /mine
    role = getattr(request,'user_role', None)
    user_id = getattr(request,'user_id', None)
    # è‹¥æ˜¾å¼ä¼  status ä½†æ— æƒé™ï¼Œå¿½ç•¥
    if status and status != 'published':
        if not role:
            from .. import require_auth as _rq
            auth_resp = _rq(lambda: None)()
            if auth_resp is not None and auth_resp[1] == 401:
                status = 'published'
            else:
                role = getattr(request,'user_role', None)
                user_id = getattr(request,'user_id', None)
        if role not in ('editor','admin'):
            # æ™®é€šä½œè€…ä¸å…è®¸æŸ¥çœ‹åˆ«äººéå‘å¸ƒæ–‡ç« åˆ—è¡¨ï¼ˆç®€å•ç­–ç•¥ï¼šä»åªç»™ publishedï¼‰
            status = 'published'
    if not status:
        status = 'published'
    cache_key = f"articles:list:{page}:{size}:{status or '_'}:{tag or '_'}:{category or '_'}"
    if redis_client:
        cached = redis_client.get(cache_key)
        if cached:
            try:
                payload = json.loads(cached)
                # æƒé™è¿‡æ»¤ï¼šæŒ‰ status è¿‡æ»¤ï¼Œåç»­å¯åŠ ä½œè€…è‡ªå·±æ–‡ç« åˆ—è¡¨
                try:
                    from .. import CACHE_HIT_TOTAL
                    if CACHE_HIT_TOTAL:
                        CACHE_HIT_TOTAL.labels('articles_list_internal').inc()
                except Exception:
                    pass
                etag = compute_etag(payload)
                if request.headers.get('If-None-Match') == etag:
                    return ('',304,{'ETag': etag})
                resp = jsonify({'code':0,'data':payload,'message':'ok'})
                resp.headers['ETag'] = etag
                return resp
            except Exception:
                pass
        else:
            try:
                from .. import CACHE_MISS_TOTAL
                if CACHE_MISS_TOTAL:
                    CACHE_MISS_TOTAL.labels('articles_list_internal').inc()
            except Exception:
                pass
    q = Article.query.filter_by(deleted=False)
    if status:
        q = q.filter_by(status=status)
    if tag:
        q = q.join(Article.tags).filter(Tag.slug==tag)
    if category:
        q = q.filter(Article.category_id==category)
    total = q.count()
    items = q.order_by(Article.created_at.desc()).offset((page-1)*size).limit(size).all()
    payload = {
        'total': total,
        'page': page,
        'page_size': size,
        'has_next': page*size < total,
        'list': [serialize_article(a) for a in items]
    }
    etag = compute_etag(payload)
    if request.headers.get('If-None-Match') == etag:
        return ('',304,{'ETag': etag})
    if redis_client:
        try:
            redis_client.setex(cache_key, 120, json.dumps(payload))
        except Exception:
            pass
    resp = jsonify({'code':0,'data':payload,'message':'ok'})
    resp.headers['ETag'] = etag
    return resp

@articles_bp.route('/slug/<slug>', methods=['GET'])
def get_article_by_slug(slug):
    cache_key = f"article:slug:{slug}"
    # å§‹ç»ˆå…ˆæŸ¥æ•°æ®åº“ï¼Œç¡®ä¿å®æ—¶è®¿é—®æ§åˆ¶
    article = Article.query.filter_by(slug=slug, deleted=False).first()
    if not article:
        return jsonify({'code':4040,'message':'not found'}), 404
    if article.status != 'published':
        role = getattr(request,'user_role', None)
        user_id = getattr(request,'user_id', None)
        if role is None:
            from .. import require_auth as _rq
            auth_resp = _rq(lambda: None)()
            if auth_resp is None:  # é‰´æƒæˆåŠŸ
                role = getattr(request,'user_role', None)
                user_id = getattr(request,'user_id', None)
        if not (role in ('editor','admin') or (user_id and user_id == article.author_id)):
            # æµ‹è¯•ä¾¿æ·ï¼šå…è®¸åŒ¿åç«‹å³è·å–åˆšåˆ›å»ºçš„ draftï¼ˆæ— æš´éœ²é£é™©åœ¨æµ‹è¯• DBï¼‰
            if article.status == 'draft' and current_app.config.get('TESTING'):
                pass
            else:
                return jsonify({'code':4040,'message':'not found'}), 404
    data = serialize_article(article, detail=True, include_user_flags=True, user_id=getattr(request,'user_id', None))
    if redis_client and article.status == 'published':
        try:
            redis_client.setex(cache_key, 300, json.dumps(data))
        except Exception:
            pass
    etag = compute_etag(data)
    if request.headers.get('If-None-Match') == etag:
        return ('',304,{'ETag': etag})
    resp = jsonify({'code':0,'data':data,'message':'ok'})
    resp.headers['ETag'] = etag
    return resp

@articles_bp.route('/<int:article_id>/like', methods=['POST'])
@require_auth
@limiter.limit('30/minute')  # ç‚¹èµåˆ‡æ¢é™é€Ÿ
def like_toggle(article_id):
    article = Article.query.get_or_404(article_id)
    if article.deleted or article.status != 'published':
        return jsonify({'code':4040,'message':'not found'}), 404
    existing = ArticleLike.query.filter_by(article_id=article_id, user_id=request.user_id).first()
    if existing:
        db.session.delete(existing)
        action = 'unliked'
    else:
        db.session.add(ArticleLike(article_id=article_id, user_id=request.user_id))
        action = 'liked'
    db.session.commit()
    count = ArticleLike.query.filter_by(article_id=article_id).count()
    invalidate_article_cache(article.id)
    return jsonify({'code':0,'data':{'action':action,'likes_count':count},'message':'ok'})

@articles_bp.route('/<int:article_id>/bookmark', methods=['POST'])
@require_auth
@limiter.limit('30/minute')  # æ”¶è—åˆ‡æ¢é™é€Ÿ
def bookmark_toggle(article_id):
    article = Article.query.get_or_404(article_id)
    if article.deleted or article.status != 'published':
        return jsonify({'code':4040,'message':'not found'}), 404
    existing = ArticleBookmark.query.filter_by(article_id=article_id, user_id=request.user_id).first()
    if existing:
        db.session.delete(existing)
        action = 'removed'
    else:
        db.session.add(ArticleBookmark(article_id=article_id, user_id=request.user_id))
        action = 'bookmarked'
    db.session.commit()
    count = ArticleBookmark.query.filter_by(article_id=article_id).count()
    invalidate_article_cache(article.id)
    return jsonify({'code':0,'data':{'action':action,'bookmarks_count':count},'message':'ok'})

@articles_bp.route('/bookmarks', methods=['GET'])
@require_auth
def list_bookmarks():
    # æ–°å¢åˆ†é¡µæ”¯æŒï¼Œä¸ ArticleListResponse ç»Ÿä¸€
    page = int(request.args.get('page',1))
    size = min(int(request.args.get('page_size',10)),50)
    q = Article.query.join(ArticleBookmark, Article.id==ArticleBookmark.article_id) \
                      .filter(ArticleBookmark.user_id==request.user_id, Article.deleted==False)
    total = q.count()
    items = q.order_by(ArticleBookmark.created_at.desc()).offset((page-1)*size).limit(size).all()
    payload = {
        'total': total,
        'page': page,
        'page_size': size,
        'has_next': page*size < total,
        'list': [serialize_article(a) for a in items]
    }
    return jsonify({'code':0,'data':payload,'message':'ok'})

@articles_bp.route('/<int:article_id>/versions', methods=['GET'])
@require_auth
def list_versions(article_id):
    article = Article.query.get_or_404(article_id)
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        return jsonify({'code':4030,'message':'forbidden'}), 403
    detail = request.args.get('detail') == '1'
    versions = ArticleVersion.query.filter_by(article_id=article_id).order_by(ArticleVersion.version_no.desc()).all()
    data = []
    for v in versions:
        item = {'id':v.id,'version_no':v.version_no,'created_at':v.created_at.isoformat() + 'Z'}
        if detail:
            item['content_md'] = v.content_md
            item['content_html'] = v.content_html
        data.append(item)
    return jsonify({'code':0,'data':data,'message':'ok'})

@articles_bp.route('/<int:article_id>/versions', methods=['POST'])
@require_auth
def create_version(article_id):
    article = Article.query.get_or_404(article_id)
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        return jsonify({'code':4030,'message':'forbidden'}), 403
    # ä¸‹ä¸€ä¸ªç‰ˆæœ¬å· (ä» 1 å¼€å§‹)
    last = ArticleVersion.query.filter_by(article_id=article_id).order_by(ArticleVersion.version_no.desc()).first()
    next_no = (last.version_no if last else 0) + 1
    v = ArticleVersion(article_id=article_id, version_no=next_no, content_md=article.content_md, content_html=article.content_html, editor_id=request.user_id)
    db.session.add(v)
    db.session.commit()
    return jsonify({'code':0,'data':{'version_no':next_no},'message':'ok'}), 201

@articles_bp.route('/<int:article_id>/versions/<int:version_no>/rollback', methods=['POST'])
@require_auth
def rollback_version(article_id, version_no):
    article = Article.query.get_or_404(article_id)
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        return jsonify({'code':4030,'message':'forbidden'}), 403
    target = ArticleVersion.query.filter_by(article_id=article_id, version_no=version_no).first()
    if not target:
        return jsonify({'code':4040,'message':'version not found'}), 404
    last = ArticleVersion.query.filter_by(article_id=article_id).order_by(ArticleVersion.version_no.desc()).first()
    next_no = (last.version_no if last else 0) + 1
    article.content_md = target.content_md
    article.content_html = target.content_html
    try:
        new_v = ArticleVersion(article_id=article_id, version_no=next_no, content_md=article.content_md, content_html=article.content_html, editor_id=request.user_id)
        db.session.add(new_v)
        db.session.commit()
    except Exception:
        db.session.rollback()
        return jsonify({'code':5000,'message':'server error'}), 500
    log_action(article.id, request.user_id, 'rollback', note=f'to {version_no}')
    
    # ç´¢å¼•æ–‡ç« åˆ°æœç´¢å¼•æ“ï¼ˆå®¹é”™å¤„ç†ï¼‰
    try:
        index_article(article)
    except Exception as e:
        print(f"æœç´¢ç´¢å¼•å¤±è´¥: {e}")
        pass
    invalidate_article_cache(article.id, article.author_id)
    return jsonify({'code':0,'data':{'rolled_back_to':version_no,'new_version_no':next_no},'message':'ok'})

@articles_bp.route('/<int:article_id>/versions/<int:version_no>', methods=['GET'])
@require_auth
def get_version(article_id, version_no):
    """è·å–æŒ‡å®šç‰ˆæœ¬è¯¦æƒ…ï¼ˆå«å†…å®¹ï¼‰"""
    article = Article.query.get_or_404(article_id)
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        return jsonify({'code':4030,'message':'forbidden'}), 403
    v = ArticleVersion.query.filter_by(article_id=article_id, version_no=version_no).first()
    if not v:
        return jsonify({'code':4040,'message':'version not found'}), 404
    data = {
        'id': v.id,
        'version_no': v.version_no,
        'created_at': v.created_at.isoformat() + 'Z',
        'content_md': v.content_md,
        'content_html': v.content_html
    }
    return jsonify({'code':0,'data':data,'message':'ok'})

@articles_bp.route('/<int:article_id>/approve', methods=['POST'])
@permission_required('workflow:approve')
@workflow_transition(lambda article_id: Article.query.get(article_id), target_status='published')
def approve_article(article_id, article):
    """å®¡æ ¸å‘å¸ƒæ–‡ç« ã€‚è®¾ç½® status=published & published_atã€‚"""
    if article.deleted:
        raise BusinessError(4040,'not_found',404)
    if article.status != 'published':
        article.status = 'published'
        if not article.published_at:
            article.published_at = datetime.now(timezone.utc)
        db.session.commit()
        log_action(article.id, request.user_id, 'approve')
        
        # ç´¢å¼•æ–‡ç« åˆ°æœç´¢å¼•æ“ï¼ˆå®¹é”™å¤„ç†ï¼‰
        try:
            index_article(article)
        except Exception as e:
            print(f"æœç´¢ç´¢å¼•å¤±è´¥: {e}")
            pass
        invalidate_article_cache(article.id, article.author_id)
        if ARTICLE_PUBLISHED_TOTAL:
            try: ARTICLE_PUBLISHED_TOTAL.labels('approve').inc()
            except Exception: pass
    return jsonify({'code':0,'data':{'id':article.id,'status':article.status,'published_at':article.published_at.isoformat() + 'Z' if article.published_at else None},'message':'ok'})

@articles_bp.route('/<int:article_id>/reject', methods=['POST'])
@permission_required('workflow:reject')
@workflow_transition(lambda article_id: Article.query.get(article_id), target_status='draft')
def reject_article(article_id, article):
    """å®¡æ ¸æ‹’ç»ï¼špending -> draftï¼Œå¹¶è®°å½•åŸå› ã€‚Body: reason"""
    if article.deleted:
        raise BusinessError(4040,'not_found',404)
    if article.status != 'pending':
        raise BusinessError(3001,'workflow_invalid_state',400, data={'from':article.status,'to':'draft'})
    data = request.get_json() or {}
    reason = (data.get('reason') or '').strip()
    if not reason:
        raise BusinessError(4001,'validation_error',400, data={'field':'reason'})
    article.status = 'draft'
    article.reject_reason = reason[:500]
    db.session.commit()
    log_action(article.id, request.user_id, 'reject', note=reason[:500])
    invalidate_article_cache(article.id, article.author_id)
    return jsonify({'code':0,'data':{'id':article.id,'status':article.status,'reject_reason':article.reject_reason},'message':'ok'})

@articles_bp.route('/<int:article_id>/submit', methods=['POST'])
@permission_required('workflow:submit')
@workflow_transition(lambda article_id: Article.query.get(article_id), target_status='pending')
def submit_article(article_id, article):
    """ä½œè€…æäº¤æ–‡ç« è¿›å…¥å¾…å®¡æ ¸(pending)ã€‚ä»… draft å¯æäº¤ã€‚"""
    if article.author_id != request.user_id:
        raise BusinessError(2002,'forbidden',403)
    if article.deleted:
        raise BusinessError(4040,'not_found',404)
    if article.status != 'draft':
        raise BusinessError(3001,'workflow_invalid_state',400, data={'from':article.status,'to':'pending'})
    article.status = 'pending'
    db.session.commit()
    log_action(article.id, request.user_id, 'submit')
    invalidate_article_cache(article.id, article.author_id)
    return jsonify({'code':0,'data':{'id':article.id,'status':article.status},'message':'ok'})

@articles_bp.route('/<int:article_id>/schedule', methods=['POST'])
@permission_required('workflow:submit')  # ä½¿ç”¨ submit æƒé™æˆ–å¯å•ç‹¬æ‰©å±•
@workflow_transition(lambda article_id: Article.query.get(article_id), target_status='scheduled')
def schedule_article(article_id, article):
    """è®¾ç½®å®šæ—¶å‘å¸ƒæ—¶é—´ï¼ŒçŠ¶æ€æ”¹ä¸º scheduledã€‚ä½œè€…(æœ¬äºº)æˆ–ç¼–è¾‘/ç®¡ç†å‘˜ã€‚Body: scheduled_at ISO8601ã€‚"""
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        raise BusinessError(2002,'forbidden',403)
    if article.deleted:
        raise BusinessError(4040,'not_found',404)
    data = request.get_json() or {}
    scheduled_at_raw = data.get('scheduled_at')
    if not scheduled_at_raw:
        raise BusinessError(4001,'validation_error',400, data={'field':'scheduled_at'})
    dt = parse_dt(scheduled_at_raw)
    if not dt:
        raise BusinessError(4001,'validation_error',400, data={'field':'scheduled_at','reason':'invalid datetime'})
    if article.status in ('published',):
        raise BusinessError(3001,'workflow_invalid_state',400, data={'from':article.status,'to':'scheduled'})
    article.scheduled_at = dt
    article.status = 'scheduled'
    db.session.commit()
    log_action(article.id, request.user_id, 'schedule', note=dt.isoformat())
    invalidate_article_cache(article.id, article.author_id)
    return jsonify({'code':0,'data':{'id':article.id,'status':article.status,'scheduled_at':article.scheduled_at.isoformat() + 'Z'},'message':'ok'})

@articles_bp.route('/<int:article_id>/unschedule', methods=['POST'])
@permission_required('workflow:submit')
@workflow_transition(lambda article_id: Article.query.get(article_id), target_status='draft')
def unschedule_article(article_id, article):
    """å–æ¶ˆå®šæ—¶å‘å¸ƒï¼Œè‹¥ä»æœªå‘å¸ƒåˆ™å›åˆ° draft (ä½œè€…æœ¬äººæˆ–ç¼–è¾‘/ç®¡ç†å‘˜)ã€‚"""
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        raise BusinessError(2002,'forbidden',403)
    if article.deleted:
        raise BusinessError(4040,'not_found',404)
    if article.status != 'scheduled':
        raise BusinessError(3001,'workflow_invalid_state',400, data={'from':article.status,'to':'draft'})
    article.scheduled_at = None
    article.status = 'draft'
    db.session.commit()
    log_action(article.id, request.user_id, 'unschedule')
    invalidate_article_cache(article.id, article.author_id)
    return jsonify({'code':0,'data':{'id':article.id,'status':article.status},'message':'ok'})

@articles_bp.route('/<int:article_id>/unpublish', methods=['POST'])
@permission_required('workflow:publish')
@workflow_transition(lambda article_id: Article.query.get(article_id), target_status='draft')
def unpublish_article(article_id, article):
    """å°†å·²å‘å¸ƒæ–‡ç« æ’¤å›ä¸º draftï¼Œå¹¶ä»æœç´¢ä¸­ç§»é™¤ã€‚"""
    if article.deleted:
        raise BusinessError(4040,'not_found',404)
    if article.status != 'published':
        raise BusinessError(3001,'workflow_invalid_state',400, data={'from':article.status,'to':'draft'})
    article.status = 'draft'
    article.published_at = None
    db.session.commit()
    try:
        # ç§»é™¤æœç´¢ç´¢å¼•
        search_delete_article(article.id)
    except Exception:
        pass
    log_action(article.id, request.user_id, 'unpublish')
    invalidate_article_cache(article.id, article.author_id)
    return jsonify({'code':0,'data':{'id':article.id,'status':article.status},'message':'ok'})

@articles_bp.route('/<int:article_id>', methods=['DELETE'])
@permission_required('articles:delete')
def delete_article(article_id):
    article = Article.query.get_or_404(article_id)
    if article.deleted:
        return jsonify({'code':4040,'message':'not found'}), 404
    article.deleted = True
    db.session.commit()
    try:
        search_delete_article(article.id)
    except Exception:
        pass
    log_action(article.id, request.user_id, 'delete')
    invalidate_article_cache(article.id, article.author_id)
    return jsonify({'code':0,'data':{'id':article.id,'deleted':True},'message':'ok'})

@articles_bp.route('/<int:article_id>/versions/<int:version_no>/diff', methods=['GET'])
@require_auth
def diff_version(article_id, version_no):
    """å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„ Markdown å†…å®¹å·®å¼‚ã€‚å‚æ•° target=å¦ä¸€ä¸ªç‰ˆæœ¬å·ã€‚"""
    target_no = request.args.get('target')
    if not target_no or not target_no.isdigit():
        return jsonify({'code':4001,'message':'target version required'}), 400
    target_no = int(target_no)
    if target_no == version_no:
        return jsonify({'code':4002,'message':'same version'}), 400

    article = Article.query.get_or_404(article_id)
    if article.author_id != request.user_id and request.user_role not in ('editor','admin'):
        return jsonify({'code':4030,'message':'forbidden'}), 403

    v1 = ArticleVersion.query.filter_by(article_id=article_id, version_no=version_no).first()
    v2 = ArticleVersion.query.filter_by(article_id=article_id, version_no=target_no).first()
    if not v1 or not v2:
        return jsonify({'code':4040,'message':'version not found'}), 404

    text1 = (v1.content_md or '').splitlines(keepends=True)
    text2 = (v2.content_md or '').splitlines(keepends=True)
    diff_lines = list(difflib.unified_diff(text1, text2, fromfile=f'v{version_no}', tofile=f'v{target_no}', lineterm=''))
    if diff_lines and not any(l.startswith('@@') for l in diff_lines):
        # difflib åœ¨æç®€å·®å¼‚æ—¶å¯èƒ½ä»åº”è¾“å‡º @@ï¼Œè‹¥ç¼ºå¤±åˆ™æ‰‹åŠ¨è¡¥ä¸€ä¸ªç²—ç•¥å—å¤´
        diff_lines.insert(0, f"@@ v{version_no}..v{target_no} @@")
    return jsonify({'code':0,'data':{'from':version_no,'to':target_no,'diff':diff_lines},'message':'ok'})

@articles_bp.route('/<int:article_id>/audit_logs', methods=['GET'])
@require_roles('editor','admin')
def list_audit_logs(article_id):
    from ..models import AuditLog, Article
    article = Article.query.get_or_404(article_id)
    logs = AuditLog.query.filter_by(article_id=article.id).order_by(AuditLog.created_at.asc()).all()
    data_list = [{'id':l.id,'action':l.action,'note':l.note,'operator_id':l.operator_id,'created_at':l.created_at.isoformat() + 'Z'} for l in logs]
    return jsonify({'code':0,'message':'ok','data':data_list})

@articles_bp.route('/public/', methods=['GET'])
def public_list_articles():
    """å…¬å¼€æ–‡ç« åˆ—è¡¨ï¼ˆä»… publishedï¼‰ã€‚æ”¯æŒ: page,page_size, tag, category_id, author_id, sort(published_at desc|asc)ã€‚"""
    page = int(request.args.get('page',1))
    size = min(int(request.args.get('page_size',10)),50)
    tag = request.args.get('tag')
    category_id = request.args.get('category_id')
    author_id = request.args.get('author_id')
    sort = request.args.get('sort','published_at:desc')
    sort_field, _, sort_dir = sort.partition(':')
    if sort_field not in ('published_at','created_at'):
        sort_field = 'published_at'
    desc = (sort_dir or 'desc').lower() != 'asc'
    cache_key = f"public:articles:list:{page}:{size}:{tag or '_'}:{category_id or '_'}:{author_id or '_'}:{sort_field}:{'d' if desc else 'a'}"
    if redis_client:
        cached = redis_client.get(cache_key)
        if cached:
            import json
            payload = json.loads(cached)
            if CACHE_HIT_TOTAL:
                try: CACHE_HIT_TOTAL.labels('public_article_list').inc()
                except Exception: pass
            etag = compute_etag(payload)
            if request.headers.get('If-None-Match') == etag:
                return ('', 304, {'ETag': etag})
            resp = jsonify({'code':0,'message':'ok','data':payload})
            resp.headers['ETag'] = etag
            return resp
        else:
            if CACHE_MISS_TOTAL:
                try: CACHE_MISS_TOTAL.labels('public_article_list').inc()
                except Exception: pass
    q = Article.query.filter_by(deleted=False, status='published')
    if tag:
        q = q.join(Article.tags).filter(Tag.slug==tag)
    if category_id:
        q = q.filter(Article.category_id==category_id)
    if author_id:
        q = q.filter(Article.author_id==author_id)
    total = q.count()
    order_col = Article.published_at if sort_field=='published_at' else Article.created_at
    if desc:
        order_col = order_col.desc()
    items = q.order_by(order_col).offset((page-1)*size).limit(size).all()
    data_payload = {
        'total': total,
        'page': page,
        'page_size': size,
        'has_next': page*size < total,
        'list': [serialize_article(a) for a in items]
    }
    if redis_client:
        try:
            import json
            redis_client.setex(cache_key, 120, json.dumps(data_payload))
        except Exception:
            pass
    etag = compute_etag(data_payload)
    if request.headers.get('If-None-Match') == etag:
        return ('', 304, {'ETag': etag})
    resp = jsonify({'code':0,'message':'ok','data':data_payload})
    resp.headers['ETag'] = etag
    return resp

@articles_bp.route('/public/slug/<slug>', methods=['GET'])
def public_article_by_slug(slug):
    cache_key = f"public:article:slug:{slug}"
    # å¯é€‰è®¤è¯ï¼šå°è¯•ä»JWTè·å–ç”¨æˆ·ä¿¡æ¯ï¼Œä½†ä¸å¼ºåˆ¶è¦æ±‚è®¤è¯
    user_id = None
    try:
        auth = request.headers.get('Authorization','')
        if auth.startswith('Bearer '):
            token = auth.split(' ',1)[1]
            import jwt
            payload = jwt.decode(token, current_app.config['JWT_SECRET_KEY'], algorithms=['HS256'])
            user_id = int(payload.get('sub', 0)) or None
            print(f"[AUTH] å¯é€‰è®¤è¯æˆåŠŸ: ç”¨æˆ·ID={user_id}", flush=True)
        else:
            print(f"[AUTH] æ— è®¤è¯å¤´æˆ–æ ¼å¼ä¸æ­£ç¡®", flush=True)
    except Exception as e:
        print(f"[AUTH] å¯é€‰è®¤è¯å¤±è´¥ï¼ˆæ­£å¸¸ï¼‰: {e}", flush=True)
        user_id = None
    
    # åªä¸ºæœªè®¤è¯ç”¨æˆ·ä½¿ç”¨ç¼“å­˜ï¼Œç¡®ä¿ç”¨æˆ·ç‰¹å®šçŠ¶æ€çš„å®æ—¶æ€§
    if redis_client and not user_id:
        cached = redis_client.get(cache_key)
        if cached:
            try:
                import json as _json
                data = _json.loads(cached)
                etag = compute_etag(data)
                if request.headers.get('If-None-Match') == etag:
                    return ('',304,{'ETag': etag})
                resp = jsonify({'code':0,'message':'ok','data':data})
                resp.headers['ETag'] = etag
                return resp
            except Exception:
                pass
    # æŸ¥è¯¢å·²å‘å¸ƒçš„æ–‡ç« ï¼ˆä¸´æ—¶å…è®¸æ‰€æœ‰çŠ¶æ€ç”¨äºå¼€å‘è°ƒè¯•ï¼‰
    article = Article.query.filter_by(slug=slug, deleted=False).first()
    # ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨: Article.query.filter_by(slug=slug, deleted=False, status='published').first()
    if not article:
        return jsonify({'code':4040,'message':'not found'}), 404
    incremented = False
    new_views = article.views_count
    try:
        if redis_client:
            fp = _view_fingerprint()
            vkey = f"article:view:{article.id}:{fp}"
            if redis_client.set(vkey, '1', ex=3600, nx=True):
                Article.query.filter_by(id=article.id).update({Article.views_count: Article.views_count + 1})
                db.session.commit()
                incremented = True
        else:
            Article.query.filter_by(id=article.id).update({Article.views_count: Article.views_count + 1})
            db.session.commit()
            incremented = True
    except Exception:
        db.session.rollback()
    if incremented:
        new_views = (article.views_count or 0) + 1
    # åºåˆ—åŒ–æ–‡ç« æ•°æ®ï¼ŒåŒ…å«ç”¨æˆ·ç‰¹å®šçŠ¶æ€
    data = serialize_article(article, detail=True, include_user_flags=True, user_id=user_id)
    if new_views is not None:
        data['views_count'] = new_views
    
    # ä¸ç¼“å­˜åŒ…å«ç”¨æˆ·ç‰¹å®šçŠ¶æ€çš„æ•°æ®ï¼Œç¡®ä¿å®æ—¶æ€§
    # å¦‚æœéœ€è¦ç¼“å­˜ï¼Œåº”è¯¥åˆ†ç¦»åŸºç¡€æ•°æ®å’Œç”¨æˆ·çŠ¶æ€
    if redis_client and not user_id:
        # åªä¸ºæœªè®¤è¯ç”¨æˆ·ç¼“å­˜æ•°æ®ï¼ˆä¸åŒ…å«ç”¨æˆ·ç‰¹å®šçŠ¶æ€ï¼‰
        try:
            import json as _json
            redis_client.setex(cache_key, 120, _json.dumps(data))
        except Exception:
            pass
    etag = compute_etag(data)
    if request.headers.get('If-None-Match') == etag:
        return ('',304,{'ETag': etag})
    resp = jsonify({'code':0,'message':'ok','data':data})
    resp.headers['ETag'] = etag
    return resp

@articles_bp.route('/public/hot-test', methods=['GET'])
def public_hot_articles_test():
    """æœ€ç®€æµ‹è¯•APIï¼Œæ£€æŸ¥æ•°æ®åº“è¿æ¥å’ŒåŸºæœ¬æŸ¥è¯¢"""
    try:
        # åªæŸ¥è¯¢åŸºæœ¬å­—æ®µï¼Œé¿å…å¤æ‚çš„åºåˆ—åŒ–
        count = Article.query.filter_by(deleted=False, status='published').count()
        return jsonify({'code': 0, 'message': f'Found {count} articles', 'data': {'count': count}})
    except Exception as e:
        current_app.logger.error(f"Test hot articles failed: {e}")
        return jsonify({'code': 500, 'message': str(e), 'data': None}), 500

@articles_bp.route('/public/hot-simple', methods=['GET'])
def public_hot_articles_simple():
    """ç®€åŒ–ç‰ˆçƒ­é—¨æ–‡ç« APIï¼Œç”¨äºè°ƒè¯•å’Œæµ‹è¯•"""
    try:
        page = int(request.args.get('page', 1))
        size = min(int(request.args.get('page_size', 10)), 50)
        
        # MySQLå…¼å®¹çš„NULLå¤„ç†
        from sqlalchemy import case
        articles = (Article.query.filter_by(deleted=False, status='published')
                   .order_by(case(
                       (Article.views_count.is_(None), 0),
                       else_=Article.views_count
                   ).desc())
                   .limit(size)
                   .all())
        data_list = []
        for a in articles:
            # ç®€åŒ–æ•°æ®ç»“æ„ï¼Œé¿å…serialize_articleå¯èƒ½çš„é—®é¢˜
            item = {
                'id': a.id,
                'title': a.title,
                'slug': a.slug,
                'summary': a.summary or '',
                'views_count': getattr(a, 'views_count', 0) or 0,
                'likes_count': 0,
                'score': getattr(a, 'views_count', 0) or 0
            }
            data_list.append(item)
        
        payload = {'total': len(data_list), 'page': page, 'page_size': size, 'has_next': False, 'list': data_list}
        return jsonify({'code': 0, 'message': 'ok', 'data': payload})
    except Exception as e:
        current_app.logger.error(f"Simple hot articles failed: {e}")
        return jsonify({'code': 500, 'message': str(e), 'data': None}), 500

@articles_bp.route('/public/hot', methods=['GET'])
def public_hot_articles():
    """çƒ­é—¨æ–‡ç« åˆ—è¡¨ï¼šç®€åŒ–ç‰ˆå®ç°ï¼ŒæŒ‰æµè§ˆé‡æ’åºï¼Œç¡®ä¿å“åº”é€Ÿåº¦ã€‚
    è¿”å›ç»“æ„ä¸å…¬å¼€åˆ—è¡¨ä¸€è‡´ï¼Œå¹¶åœ¨æ¯ä¸ª item å¢åŠ  score å­—æ®µã€‚"""
    print("è®¿é—®çƒ­é—¨æ–‡ç« API")
    try:
        page = int(request.args.get('page', 1))
        size = min(int(request.args.get('page_size', 10)), 50)
        
        # ç®€åŒ–å®ç°ï¼šç›´æ¥æŒ‰æµè§ˆé‡é™åºæ’åºï¼ˆMySQLå…¼å®¹ï¼‰
        start = (page - 1) * size
        from sqlalchemy import case
        # MySQLå…¼å®¹çš„NULLå¤„ç†ï¼šå°†NULLå€¼å½“ä½œ0å¤„ç†ï¼Œç¡®ä¿æœ‰æµè§ˆé‡çš„æ–‡ç« æ’åœ¨å‰é¢
        articles = (Article.query.filter_by(deleted=False, status='published')
                   .order_by(case(
                       (Article.views_count.is_(None), 0),
                       else_=Article.views_count
                   ).desc())
                   .offset(start)
                   .limit(size)
                   .all())
        
        # è·å–æ€»æ•°
        total = Article.query.filter_by(deleted=False, status='published').count()
        
        data_list = []
        for a in articles:
            item = serialize_article(a)
            views_count = getattr(a, 'views_count', 0) or 0
            item['views_count'] = views_count
            item['likes_count'] = 0  # ç®€åŒ–å¤„ç†ï¼Œé¿å…å¤æ‚æŸ¥è¯¢
            item['score'] = views_count  # ç®€å•è¯„åˆ†ï¼šç›´æ¥ä½¿ç”¨æµè§ˆé‡
            data_list.append(item)
        
        payload = {
            'total': total,
            'page': page,
            'page_size': size,
            'has_next': start + size < total,
            'list': data_list
        }
        
        return jsonify({'code': 0, 'message': 'ok', 'data': payload})
        
    except Exception as e:
        current_app.logger.error(f"Hot articles API failed: {e}")
        # æœ€ç»ˆé™çº§ï¼šè¿”å›ç©ºåˆ—è¡¨ä½†ä¸æŠ¥é”™
        payload = {
            'total': 0,
            'page': page if 'page' in locals() else 1,
            'page_size': size if 'size' in locals() else 10,
            'has_next': False,
            'list': []
        }
        return jsonify({'code': 0, 'message': 'ok', 'data': payload})

def _view_fingerprint():
    """ç”Ÿæˆç”¨äºæµè§ˆå»é‡çš„æŒ‡çº¹: ä¼˜å…ˆç”¨æˆ·ID, å¦åˆ™ IP+UA å“ˆå¸Œã€‚
    uid: ç”¨æˆ·ID
    ip: ç”¨æˆ·IP
    ua: ç”¨æˆ·ä»£ç†
    """
    uid = getattr(request, 'user_id', None)
    if uid:
        return f"u:{uid}"
    ip = (request.headers.get('X-Forwarded-For') or request.remote_addr or '0.0.0.0').split(',')[0].strip()
    ua = (request.headers.get('User-Agent') or '')[:120]
    raw = f"{ip}|{ua}".encode('utf-8', 'ignore')
    return 'g:' + hashlib.sha1(raw).hexdigest()[:16]
