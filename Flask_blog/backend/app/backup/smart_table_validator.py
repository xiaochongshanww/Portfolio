"""
æ™ºèƒ½è¡¨éªŒè¯å™¨

åŸºäº SQLAlchemy æ¨¡å‹åå°„å’Œå¤šæºéªŒè¯çš„åŠ¨æ€è¡¨å‘ç°ç³»ç»Ÿ
é¿å…ç¡¬ç¼–ç è¡¨åï¼Œè‡ªåŠ¨é€‚åº”é¡¹ç›®ç»“æ„å˜åŒ–
"""

import re
import logging
from pathlib import Path
from typing import Dict, Set, List, Tuple, Any, Optional
from dataclasses import dataclass
from enum import Enum

from flask import current_app
from sqlalchemy import text
from .. import db


class TableImportance(Enum):
    """è¡¨é‡è¦æ€§çº§åˆ«"""
    CRITICAL = "critical"      # æ ¸å¿ƒä¸šåŠ¡è¡¨ï¼Œä¸¢å¤±ä¼šå¯¼è‡´ç³»ç»Ÿæ— æ³•è¿è¡Œ
    IMPORTANT = "important"    # é‡è¦åŠŸèƒ½è¡¨ï¼Œå½±å“ä¸»è¦åŠŸèƒ½
    SYSTEM = "system"          # ç³»ç»Ÿç®¡ç†è¡¨ï¼Œå½±å“åå°åŠŸèƒ½  
    RELATIONSHIP = "relationship"  # å…³è”è¡¨ï¼Œç»´æŠ¤æ•°æ®å…³ç³»
    OPTIONAL = "optional"      # å¯é€‰åŠŸèƒ½è¡¨ï¼Œä¸¢å¤±ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½


@dataclass
class TableInfo:
    """è¡¨ä¿¡æ¯æ•°æ®ç»“æ„"""
    name: str
    importance: TableImportance
    columns: List[str]
    has_foreign_keys: bool
    is_junction_table: bool
    dependencies: List[str]  # ä¾èµ–çš„å…¶ä»–è¡¨


class SQLAlchemyTableDiscovery:
    """SQLAlchemy æ¨¡å‹åå°„è¡¨å‘ç°å™¨"""
    
    @staticmethod
    def get_all_model_tables() -> Set[str]:
        """ä» SQLAlchemy æ¨¡å‹ä¸­è·å–æ‰€æœ‰è¡¨å"""
        try:
            # è·å–æ‰€æœ‰å®šä¹‰çš„æ¨¡å‹è¡¨
            model_tables = set()
            for table_name in db.metadata.tables.keys():
                model_tables.add(table_name)
            
            current_app.logger.info(f"ä» SQLAlchemy æ¨¡å‹å‘ç° {len(model_tables)} å¼ è¡¨")
            return model_tables
            
        except Exception as e:
            current_app.logger.error(f"SQLAlchemy è¡¨å‘ç°å¤±è´¥: {e}")
            return set()
    
    @staticmethod
    def get_detailed_table_info() -> Dict[str, TableInfo]:
        """è·å–è¯¦ç»†çš„è¡¨ä¿¡æ¯"""
        table_info = {}
        
        try:
            for table_name, table_obj in db.metadata.tables.items():
                # åˆ†æè¡¨ç»“æ„
                columns = [col.name for col in table_obj.columns]
                foreign_keys = list(table_obj.foreign_keys)
                
                # åˆ¤æ–­æ˜¯å¦æ˜¯å…³è”è¡¨ï¼ˆjunction tableï¼‰
                is_junction = SQLAlchemyTableDiscovery._is_junction_table(table_obj)
                
                # åˆ†æè¡¨çš„é‡è¦æ€§
                importance = SQLAlchemyTableDiscovery._assess_table_importance(
                    table_name, table_obj, is_junction
                )
                
                # åˆ†æä¾èµ–å…³ç³»
                dependencies = SQLAlchemyTableDiscovery._get_table_dependencies(table_obj)
                
                table_info[table_name] = TableInfo(
                    name=table_name,
                    importance=importance,
                    columns=columns,
                    has_foreign_keys=len(foreign_keys) > 0,
                    is_junction_table=is_junction,
                    dependencies=dependencies
                )
                
            current_app.logger.info(f"åˆ†æäº† {len(table_info)} å¼ è¡¨çš„è¯¦ç»†ä¿¡æ¯")
            return table_info
            
        except Exception as e:
            current_app.logger.error(f"è¯¦ç»†è¡¨ä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {}
    
    @staticmethod
    def _is_junction_table(table_obj) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å…³è”è¡¨"""
        # å…³è”è¡¨é€šå¸¸æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š
        # 1. åªæœ‰å¤–é”®åˆ—ï¼ˆé™¤äº†å¯èƒ½çš„æ—¶é—´æˆ³ï¼‰
        # 2. è¡¨ååŒ…å«ä¸‹åˆ’çº¿è¿æ¥ä¸¤ä¸ªå®ä½“
        # 3. åˆ—æ•°è¾ƒå°‘
        
        columns = list(table_obj.columns)
        foreign_key_columns = [col for col in columns if col.foreign_keys]
        
        # å¦‚æœå¤§éƒ¨åˆ†åˆ—éƒ½æ˜¯å¤–é”®ï¼Œå¯èƒ½æ˜¯å…³è”è¡¨
        if len(foreign_key_columns) >= 2 and len(foreign_key_columns) >= len(columns) * 0.5:
            return True
            
        # æ£€æŸ¥è¡¨åæ¨¡å¼
        if '_' in table_obj.name and len(table_obj.name.split('_')) == 2:
            # å¦‚æœè¡¨åå½¢å¦‚ "article_tags", "user_roles" ç­‰
            return True
            
        return False
    
    @staticmethod
    def _assess_table_importance(table_name: str, table_obj, is_junction: bool) -> TableImportance:
        """è¯„ä¼°è¡¨çš„é‡è¦æ€§"""
        name_lower = table_name.lower()
        
        # å…³è”è¡¨é€šå¸¸ä¸æ˜¯å…³é”®è¡¨ï¼Œä½†ä¹Ÿå¾ˆé‡è¦
        if is_junction:
            return TableImportance.RELATIONSHIP
        
        # æ ¸å¿ƒä¸šåŠ¡è¡¨æ¨¡å¼åŒ¹é…
        critical_patterns = [
            r'^users?$',           # ç”¨æˆ·è¡¨
            r'^articles?$',        # æ–‡ç« è¡¨  
            r'^categor(y|ies)$',   # åˆ†ç±»è¡¨
            r'^posts?$',           # æ–‡ç« è¡¨çš„å¦ä¸€ç§å‘½å
        ]
        
        for pattern in critical_patterns:
            if re.match(pattern, name_lower):
                return TableImportance.CRITICAL
        
        # é‡è¦åŠŸèƒ½è¡¨æ¨¡å¼åŒ¹é…
        important_patterns = [
            r'^comments?$',        # è¯„è®ºè¡¨
            r'^tags?$',           # æ ‡ç­¾è¡¨
            r'^media',            # åª’ä½“ç›¸å…³è¡¨
            r'_version',          # ç‰ˆæœ¬è¡¨
        ]
        
        for pattern in important_patterns:
            if re.search(pattern, name_lower):
                return TableImportance.IMPORTANT
        
        # ç³»ç»Ÿç®¡ç†è¡¨æ¨¡å¼åŒ¹é…
        system_patterns = [
            r'^(backup|restore|audit|log)',  # å¤‡ä»½ã€å®¡è®¡ã€æ—¥å¿—è¡¨
            r'^(admin|manage)',              # ç®¡ç†ç›¸å…³è¡¨
            r'_config',                      # é…ç½®è¡¨
        ]
        
        for pattern in system_patterns:
            if re.search(pattern, name_lower):
                return TableImportance.SYSTEM
        
        # å¯é€‰åŠŸèƒ½è¡¨æ¨¡å¼åŒ¹é…  
        optional_patterns = [
            r'^(visitor_stats|daily_stats)', # ç»Ÿè®¡è¡¨
            r'^(notification|message)',      # é€šçŸ¥æ¶ˆæ¯è¡¨
            r'_cache',                       # ç¼“å­˜è¡¨
        ]
        
        for pattern in optional_patterns:
            if re.search(pattern, name_lower):
                return TableImportance.OPTIONAL
        
        # é»˜è®¤å½’ç±»ä¸ºé‡è¦è¡¨ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        return TableImportance.IMPORTANT
    
    @staticmethod  
    def _get_table_dependencies(table_obj) -> List[str]:
        """è·å–è¡¨çš„ä¾èµ–å…³ç³»"""
        dependencies = []
        
        for fk in table_obj.foreign_keys:
            referenced_table = fk.column.table.name
            if referenced_table != table_obj.name:  # é¿å…è‡ªå¼•ç”¨
                dependencies.append(referenced_table)
        
        return list(set(dependencies))  # å»é‡


class MigrationHistoryAnalyzer:
    """è¿ç§»å†å²åˆ†æå™¨"""
    
    @staticmethod
    def get_tables_from_migrations() -> Set[str]:
        """ä»è¿ç§»å†å²ä¸­è§£æåº”è¯¥å­˜åœ¨çš„è¡¨"""
        migrations_dir = Path("migrations/versions")
        
        if not migrations_dir.exists():
            current_app.logger.warning(f"è¿ç§»ç›®å½•ä¸å­˜åœ¨: {migrations_dir}")
            return set()
        
        expected_tables = set()
        
        try:
            # æŒ‰æ–‡ä»¶åæ’åºï¼ˆåŸºæœ¬æŒ‰æ—¶é—´é¡ºåºï¼‰
            migration_files = sorted(migrations_dir.glob("*.py"))
            current_app.logger.info(f"æ‰¾åˆ° {len(migration_files)} ä¸ªè¿ç§»æ–‡ä»¶")
            
            for migration_file in migration_files:
                tables_in_migration = MigrationHistoryAnalyzer._parse_migration_file(migration_file)
                expected_tables.update(tables_in_migration['created'])
                expected_tables.difference_update(tables_in_migration['dropped'])
                
            current_app.logger.info(f"ä»è¿ç§»å†å²å‘ç° {len(expected_tables)} å¼ è¡¨")
            return expected_tables
            
        except Exception as e:
            current_app.logger.error(f"è¿ç§»å†å²åˆ†æå¤±è´¥: {e}")
            return set()
    
    @staticmethod
    def _parse_migration_file(migration_path: Path) -> Dict[str, Set[str]]:
        """è§£æå•ä¸ªè¿ç§»æ–‡ä»¶ï¼Œæå–è¡¨æ“ä½œä¿¡æ¯"""
        result = {'created': set(), 'dropped': set()}
        
        try:
            with open(migration_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åˆ†ç¦» upgrade() å’Œ downgrade() å‡½æ•°
            upgrade_section = ""
            downgrade_section = ""
            
            # æŸ¥æ‰¾ upgrade() å‡½æ•°å†…å®¹
            upgrade_match = re.search(r'def upgrade\(\):.*?(?=def downgrade\(\):|\Z)', content, re.DOTALL)
            if upgrade_match:
                upgrade_section = upgrade_match.group(0)
            
            # æŸ¥æ‰¾ downgrade() å‡½æ•°å†…å®¹
            downgrade_match = re.search(r'def downgrade\(\):.*', content, re.DOTALL)
            if downgrade_match:
                downgrade_section = downgrade_match.group(0)
            
            # åœ¨ upgrade() éƒ¨åˆ†æŸ¥æ‰¾è¡¨åˆ›å»ºæ“ä½œ
            create_patterns = [
                r"op\.create_table\(['\"](\w+)['\"]",                    # op.create_table('table_name'
                r"op\.create_table\(\s*['\"](\w+)['\"]",                # op.create_table( 'table_name'  
                r"op\.create_table\(\s*['\"](\w+)['\"]",                # with whitespace
                r"op\.create_table\(\s*[\r\n\s]*['\"](\w+)['\"]",       # multiline format
                r"CREATE TABLE ['\"]?(\w+)['\"]?",                      # CREATE TABLE table_name
                r"CREATE TABLE IF NOT EXISTS ['\"]?(\w+)['\"]?",        # CREATE TABLE IF NOT EXISTS
            ]
            
            for pattern in create_patterns:
                matches = re.findall(pattern, upgrade_section, re.IGNORECASE)
                result['created'].update(matches)
            
            # åœ¨ upgrade() éƒ¨åˆ†æŸ¥æ‰¾è¡¨åˆ é™¤æ“ä½œï¼ˆå‡çº§æ—¶åˆ é™¤çš„è¡¨æ‰æ˜¯çœŸæ­£è¢«åˆ é™¤çš„ï¼‰
            drop_patterns = [
                r"op\.drop_table\(['\"](\w+)['\"]",       # op.drop_table('table_name'
                r"DROP TABLE ['\"]?(\w+)['\"]?",          # DROP TABLE table_name
            ]
            
            for pattern in drop_patterns:
                matches = re.findall(pattern, upgrade_section, re.IGNORECASE)
                result['dropped'].update(matches)
                
        except Exception as e:
            current_app.logger.warning(f"è§£æè¿ç§»æ–‡ä»¶å¤±è´¥ {migration_path}: {e}")
        
        return result


class SmartTableValidator:
    """æ™ºèƒ½è¡¨éªŒè¯å™¨ - ä¸»ç±»"""
    
    def __init__(self):
        self.logger = current_app.logger
        self.sqlalchemy_discovery = SQLAlchemyTableDiscovery()
        self.migration_analyzer = MigrationHistoryAnalyzer()
    
    def get_expected_tables_smart(self) -> Tuple[Set[str], Dict[str, TableInfo]]:
        """æ™ºèƒ½è·å–é¢„æœŸçš„è¡¨åˆ—è¡¨å’Œè¯¦ç»†ä¿¡æ¯"""
        all_tables = set()
        table_details = {}
        
        # ä¼˜å…ˆçº§1: SQLAlchemyæ¨¡å‹ (æœ€å‡†ç¡®)
        try:
            model_tables = self.sqlalchemy_discovery.get_all_model_tables()
            table_details = self.sqlalchemy_discovery.get_detailed_table_info()
            all_tables.update(model_tables)
            self.logger.info(f"âœ… ä» SQLAlchemy æ¨¡å‹è·å–äº† {len(model_tables)} å¼ è¡¨")
        except Exception as e:
            self.logger.error(f"âŒ SQLAlchemy æ¨¡å‹è¡¨è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: è¿ç§»å†å² (è¡¥å……éªŒè¯)
        try:
            migration_tables = self.migration_analyzer.get_tables_from_migrations()
            new_from_migrations = migration_tables - all_tables
            if new_from_migrations:
                all_tables.update(new_from_migrations)
                self.logger.info(f"âœ… ä»è¿ç§»å†å²è¡¥å……äº† {len(new_from_migrations)} å¼ è¡¨: {new_from_migrations}")
        except Exception as e:
            self.logger.warning(f"âš ï¸ è¿ç§»å†å²è§£æå¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: å½“å‰æ•°æ®åº“ (å…œåº•æ–¹æ¡ˆ)
        if not all_tables:
            try:
                current_tables = self._get_current_database_tables()
                all_tables.update(current_tables)
                self.logger.info(f"âš ï¸ ä½¿ç”¨å…œåº•æ–¹æ¡ˆï¼Œä»å½“å‰æ•°æ®åº“è·å–äº† {len(current_tables)} å¼ è¡¨")
            except Exception as e:
                self.logger.error(f"âŒ æ‰€æœ‰è¡¨å‘ç°æ–¹æ¡ˆéƒ½å¤±è´¥äº†: {e}")
        
        return all_tables, table_details
    
    def _get_current_database_tables(self) -> Set[str]:
        """ä»å½“å‰æ•°æ®åº“è·å–è¡¨åˆ—è¡¨ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰"""
        try:
            result = db.session.execute(text("SHOW TABLES"))
            tables = {row[0] for row in result.fetchall()}
            return tables
        except Exception as e:
            self.logger.error(f"è·å–å½“å‰æ•°æ®åº“è¡¨å¤±è´¥: {e}")
            return set()
    
    def parse_backup_tables(self, sql_content: str) -> Set[str]:
        """ä»å¤‡ä»½SQLå†…å®¹ä¸­è§£æå‡ºåŒ…å«çš„è¡¨"""
        backup_tables = set()
        
        # æŸ¥æ‰¾ CREATE TABLE è¯­å¥
        create_patterns = [
            r"CREATE TABLE ['\"]?`?(\w+)['\"]?`?",
            r"CREATE TABLE IF NOT EXISTS ['\"]?`?(\w+)['\"]?`?",
        ]
        
        for pattern in create_patterns:
            matches = re.findall(pattern, sql_content, re.IGNORECASE | re.MULTILINE)
            backup_tables.update(matches)
        
        # ä¹Ÿæ£€æŸ¥ INSERT INTO è¯­å¥ï¼ˆæŸäº›å¤‡ä»½å¯èƒ½ä¸åŒ…å«CREATEï¼Œåªæœ‰æ•°æ®ï¼‰
        insert_patterns = [
            r"INSERT INTO ['\"]?`?(\w+)['\"]?`?",
        ]
        
        for pattern in insert_patterns:
            matches = re.findall(pattern, sql_content, re.IGNORECASE | re.MULTILINE)
            backup_tables.update(matches)
        
        self.logger.info(f"ä»å¤‡ä»½å†…å®¹ä¸­å‘ç° {len(backup_tables)} å¼ è¡¨")
        return backup_tables
    
    def validate_backup_completeness(self, sql_content: str) -> Dict[str, Any]:
        """éªŒè¯å¤‡ä»½å®Œæ•´æ€§ - æ™ºèƒ½æ–¹å¼"""
        self.logger.info("å¼€å§‹æ™ºèƒ½å¤‡ä»½å®Œæ•´æ€§éªŒè¯...")
        
        # Step 1: è·å–é¢„æœŸè¡¨å’Œè¯¦ç»†ä¿¡æ¯
        expected_tables, table_details = self.get_expected_tables_smart()
        
        # Step 2: è§£æå¤‡ä»½å†…å®¹
        backup_tables = self.parse_backup_tables(sql_content)
        
        # Step 3: è®¡ç®—å·®å¼‚
        missing_tables = expected_tables - backup_tables
        extra_tables = backup_tables - expected_tables
        
        # Step 4: åˆ†æç¼ºå¤±è¡¨çš„ä¸¥é‡æ€§
        severity_analysis = self._analyze_missing_severity(missing_tables, table_details)
        
        # Step 5: ç”ŸæˆéªŒè¯ç»“æœ
        result = {
            'complete': len(missing_tables) == 0,
            'total_expected': len(expected_tables),
            'total_in_backup': len(backup_tables),
            'missing_count': len(missing_tables),
            'extra_count': len(extra_tables),
            'missing_tables': list(missing_tables),
            'extra_tables': list(extra_tables),
            **severity_analysis,
            'can_proceed_safely': severity_analysis['severity'] in ['none', 'low'],
            'timestamp': current_app.logger.name or 'unknown'
        }
        
        self._log_validation_result(result)
        return result
    
    def _analyze_missing_severity(self, missing_tables: Set[str], table_details: Dict[str, TableInfo]) -> Dict[str, Any]:
        """åˆ†æç¼ºå¤±è¡¨çš„ä¸¥é‡ç¨‹åº¦"""
        
        categorized_missing = {
            'critical': [],
            'important': [], 
            'system': [],
            'relationship': [],
            'optional': []
        }
        
        # å¯¹ç¼ºå¤±çš„è¡¨è¿›è¡Œåˆ†ç±»
        for table_name in missing_tables:
            if table_name in table_details:
                importance = table_details[table_name].importance.value
                categorized_missing[importance].append(table_name)
            else:
                # å¯¹äºæ²¡æœ‰è¯¦ç»†ä¿¡æ¯çš„è¡¨ï¼Œä½¿ç”¨å¯å‘å¼åˆ†ç±»
                heuristic_importance = self._heuristic_classify_table(table_name)
                categorized_missing[heuristic_importance].append(table_name)
        
        # ç¡®å®šæ€»ä½“ä¸¥é‡ç¨‹åº¦
        if categorized_missing['critical']:
            severity = 'critical'
            can_proceed = False
        elif categorized_missing['important']:
            severity = 'high'
            can_proceed = False
        elif categorized_missing['system'] or categorized_missing['relationship']:
            severity = 'medium'
            can_proceed = True  # å¯ä»¥ç»§ç»­ï¼Œä½†éœ€è¦è­¦å‘Š
        else:
            severity = 'low'
            can_proceed = True
        
        # å¦‚æœæ²¡æœ‰ç¼ºå¤±è¡¨
        if not missing_tables:
            severity = 'none'
            can_proceed = True
        
        return {
            'severity': severity,
            'can_proceed': can_proceed,
            'critical_missing': categorized_missing['critical'],
            'important_missing': categorized_missing['important'],
            'system_missing': categorized_missing['system'],
            'relationship_missing': categorized_missing['relationship'],
            'optional_missing': categorized_missing['optional'],
            'recommendations': self._generate_recommendations(categorized_missing, severity)
        }
    
    def _heuristic_classify_table(self, table_name: str) -> str:
        """å¯¹æœªçŸ¥è¡¨è¿›è¡Œå¯å‘å¼åˆ†ç±»"""
        name_lower = table_name.lower()
        
        # ä½¿ç”¨ä¸ SQLAlchemy å‘ç°å™¨ç›¸åŒçš„é€»è¾‘
        if any(pattern in name_lower for pattern in ['user', 'article', 'categor']):
            return 'critical'
        elif any(pattern in name_lower for pattern in ['comment', 'tag', 'media']):
            return 'important'
        elif any(pattern in name_lower for pattern in ['backup', 'audit', 'log']):
            return 'system'
        elif '_' in name_lower and len(name_lower.split('_')) == 2:
            return 'relationship'
        else:
            return 'optional'
    
    def _generate_recommendations(self, categorized_missing: Dict[str, List[str]], severity: str) -> List[str]:
        """ç”Ÿæˆå»ºè®®å’Œæ“ä½œæŒ‡å—"""
        recommendations = []
        
        if severity == 'critical':
            recommendations.append("âŒ å‘ç°æ ¸å¿ƒè¡¨ç¼ºå¤±ï¼Œå¼ºçƒˆå»ºè®®ä¸è¦æ‰§è¡Œæ¢å¤æ“ä½œ")
            recommendations.append("ğŸ”§ è¯·æ£€æŸ¥å¤‡ä»½åˆ›å»ºè¿‡ç¨‹æ˜¯å¦æ­£ç¡®åŒ…å«æ‰€æœ‰æ ¸å¿ƒè¡¨")
            if categorized_missing['critical']:
                recommendations.append(f"ğŸ¯ ç¼ºå¤±çš„æ ¸å¿ƒè¡¨: {', '.join(categorized_missing['critical'])}")
        
        elif severity == 'high':
            recommendations.append("âš ï¸ å‘ç°é‡è¦è¡¨ç¼ºå¤±ï¼Œå»ºè®®è°¨æ…æ‰§è¡Œæ¢å¤")
            recommendations.append("ğŸ’¾ è€ƒè™‘å…ˆåˆ›å»ºå½“å‰æ•°æ®åº“çš„å¿«ç…§ä½œä¸ºå®‰å…¨æªæ–½")
            if categorized_missing['important']:
                recommendations.append(f"ğŸ“‹ ç¼ºå¤±çš„é‡è¦è¡¨: {', '.join(categorized_missing['important'])}")
        
        elif severity == 'medium':
            recommendations.append("â„¹ï¸ å‘ç°ç³»ç»Ÿè¡¨æˆ–å…³è”è¡¨ç¼ºå¤±ï¼Œå¯ä»¥ç»§ç»­æ¢å¤ä½†éœ€è¦æ³¨æ„")
            recommendations.append("ğŸ” æ¢å¤åè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½æ˜¯å¦æ­£å¸¸")
        
        elif severity == 'low':
            recommendations.append("âœ… åªæœ‰å¯é€‰è¡¨ç¼ºå¤±ï¼Œæ¢å¤åº”è¯¥æ˜¯å®‰å…¨çš„")
        
        else:
            recommendations.append("ğŸ‰ å¤‡ä»½åŒ…å«æ‰€æœ‰é¢„æœŸçš„è¡¨ï¼Œå¯ä»¥å®‰å…¨æ‰§è¡Œæ¢å¤")
        
        return recommendations
    
    def _log_validation_result(self, result: Dict[str, Any]):
        """è®°å½•éªŒè¯ç»“æœåˆ°æ—¥å¿—"""
        if result['complete']:
            self.logger.info("âœ… å¤‡ä»½å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        else:
            self.logger.warning(f"âš ï¸ å¤‡ä»½å®Œæ•´æ€§éªŒè¯å‘ç°é—®é¢˜ - ä¸¥é‡ç¨‹åº¦: {result['severity']}")
            self.logger.warning(f"ç¼ºå¤± {result['missing_count']} å¼ è¡¨: {result['missing_tables']}")
            
            if result['critical_missing']:
                self.logger.error(f"âŒ æ ¸å¿ƒè¡¨ç¼ºå¤±: {result['critical_missing']}")
            if result['important_missing']:
                self.logger.warning(f"âš ï¸ é‡è¦è¡¨ç¼ºå¤±: {result['important_missing']}")