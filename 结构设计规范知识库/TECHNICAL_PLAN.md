# 结构设计规范知识库 - 技术方案

本文档详细描述了“结构设计规范知识库”项目的技术方案，该方案结合了专业的RAG（检索增强生成）流程与用户熟悉的本地化大模型工具。

## 一、 项目目标

构建一个关于结构设计规范的智能、可交互的本地知识库。用户可以通过聊天界面提出问题，系统能够基于本地的规范文档，提供准确、可溯源的回答。

## 二、 整体技术架构

系统采用模块化设计，由用户界面、RAG后端、本地大模型三部分组成，分工明确。

1.  **用户界面 (UI)**:
    *   **工具**: **Chatbox**
    *   **职责**: 作为用户交互的图形化客户端，提供提问入口和答案展示。

2.  **RAG后端 (项目核心)**:
    *   **技术**: **Python + FastAPI**
    *   **职责**: 作为系统的“大脑”和调度中心，负责处理数据、执行RAG流程，并连接UI和本地LLM。它会暴露一个与OpenAI API兼容的接口供Chatbox调用。

3.  **大语言模型 (LLM)**:
    *   **工具**: **Ollama**
    *   **职责**: 负责运行本地大语言模型（如Llama 3, Qwen等），根据RAG后端提供的上下文和问题，生成最终的自然语言回答。

## 三、 核心工作流程

1.  用户在 **Chatbox** 中输入问题。
2.  Chatbox 将问题发送到 **RAG后端 (FastAPI服务)**。
3.  RAG后端接收到问题后，执行以下RAG核心逻辑：
    a.  **问题向量化**: 使用 **Zhipu AI `embedding-2`** 模型将问题文本转换为向量。
    b.  **知识检索**: 在 **ChromaDB** 向量数据库中进行相似性搜索，找出与问题最相关的规范条文作为上下文。
    c.  **构建提示词**: 将检索到的上下文和原始问题组合成一个结构化的提示词 (Prompt)。
4.  RAG后端将构建好的提示词发送给本地运行的 **Ollama** 服务。
5.  Ollama驱动本地LLM生成回答。
6.  RAG后端接收到Ollama的回答，并以流式（Streaming）方式传回给 **Chatbox** 展示给用户。

## 四、 具体实施阶段

### 第一阶段：项目基础建设

*   **任务**:
    *   创建项目目录结构 (`data/raw`, `data/processed`, `db`, `logs`, `src`)。
    *   初始化 `requirements.txt` 文件，并列出核心依赖。
*   **核心依赖**:
    *   `fastapi`: Web框架
    *   `uvicorn`: ASGI服务器
    *   `PyMuPDF`: PDF文件处理
    *   `paddleocr`: 中文OCR
    *   `chromadb`: 向量数据库
    *   `zhipuai`: Zhipu AI Embedding模型SDK
    *   `httpx`: 用于调用Ollama API
    *   `black`: 代码格式化

### 第二阶段：数据处理流水线

*   **任务**:
    *   实现PDF的OCR文本提取功能。
    *   实现文本清洗、去重、规范化逻辑。
    *   实现基于规范章节、条文的结构化文本切分。
*   **产出**: `data/processed` 目录下高质量、切分好的文本文件。

### 第三阶段：知识核心构建

*   **任务**:
    *   编写脚本，使用`zhipuai/embedding-2`模型对处理好的文本块进行向量化。
    *   将生成的向量、原始文本和元数据存入ChromaDB。
    *   配置ChromaDB将数据持久化存储在 `db/` 目录。

### 第四阶段：RAG后端与API开发

*   **任务**:
    *   使用FastAPI搭建Web服务。
    *   实现与OpenAI API兼容的 `/v1/chat/completions` 端点。
    *   在该端点中完整实现**第三节**所述的RAG核心工作流程。
    *   编写详细的部署和使用说明，指导用户如何配置Chatbox连接到本服务，以及如何运行Ollama。

---
